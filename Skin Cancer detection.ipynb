{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Cancer detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "from glob import glob\n",
    "from scipy import stats\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "# import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/skin-cancer/train.zip\"\n",
    "test_path = \"https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/skin-cancer/test.zip\"\n",
    "validation_path = \"https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/skin-cancer/valid.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_zip_and_extract(remote_path, local_path):\n",
    "\n",
    "    import requests, zipfile, io\n",
    "    r = requests.get(remote_path)\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    z.extractall(local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download_zip_and_extract(validation_path, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download_zip_and_extract(train_path, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download_zip_and_extract(test_path, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    targets = np_utils.to_categorical(np.array(data['target']), 3)\n",
    "    return files, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, train_targets = load_dataset('data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files, test_targets = load_dataset('data/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_files, valid_targets = load_dataset('data/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_files.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the names from the folder names in sorted order\n",
    "labels = sorted([label[11:-1] for label in glob('data/train/*/')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 total lesion categories.\n",
      "There are 2750 total lesion images.\n",
      "\n",
      "There are 2000 training lesion images.\n",
      "There are 150 validation lesion images.\n",
      "There are 600 test lesion images.\n"
     ]
    }
   ],
   "source": [
    "# print statistics about the dataset\n",
    "print('There are %d total lesion categories.' % len(labels))\n",
    "print('There are %s total lesion images.\\n' % str(len(train_files) + len(valid_files) + len(test_files)))\n",
    "print('There are %d training lesion images.' % len(train_files))\n",
    "print('There are %d validation lesion images.' % len(valid_files))\n",
    "print('There are %d test lesion images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_img(img_path, ax):\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     %matplotlib inline\n",
    "\n",
    "#     img = cv2.imread(img_path)\n",
    "#     ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20, 10))\n",
    "# for i in range(12):\n",
    "#     ax = fig.add_subplot(3, 4, i + 1, xticks=[], yticks=[])\n",
    "#     visualize_img(train_files[i], ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = cv2.imread(train_files[0])\n",
    "\n",
    "# sample.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.applications.VGG19(\n",
    "    include_top=False, \n",
    "    weights='imagenet', \n",
    "    input_tensor=None, \n",
    "    input_shape=(254, 254, 3), \n",
    "    pooling=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 254, 254, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 254, 254, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 254, 254, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 127, 127, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 127, 127, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 127, 127, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 63, 63, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 63, 63, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 63, 63, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 63, 63, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 63, 63, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 31, 31, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 31, 31, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers[:22]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(3, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model \n",
    "model_final.compile(\n",
    "    loss = \"categorical_crossentropy\", \n",
    "    optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), \n",
    "    metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 3 classes.\n",
      "Found 150 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/valid'\n",
    "batch_size = 100\n",
    "\n",
    "# Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.1,\n",
    "width_shift_range = 0.1,\n",
    "height_shift_range=0.1,\n",
    "rotation_range=10)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.1,\n",
    "width_shift_range = 0.1,\n",
    "height_shift_range=0.1,\n",
    "rotation_range=10)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size = (254, 254),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "validation_data_dir,\n",
    "target_size = (254,254),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"vgg16_1-best-classifier.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = 10\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 188s 19s/step - loss: 1.2248 - acc: 0.4680 - val_loss: 1.7142 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.52000, saving model to vgg16_1-best-classifier.h5\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 171s 17s/step - loss: 1.0708 - acc: 0.6720 - val_loss: 1.4666 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.52000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 175s 18s/step - loss: 0.9994 - acc: 0.6000 - val_loss: 1.2001 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.52000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 169s 17s/step - loss: 0.9660 - acc: 0.6380 - val_loss: 1.1985 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.52000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 165s 16s/step - loss: 0.9622 - acc: 0.6190 - val_loss: 1.1436 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.52000 to 0.52000, saving model to vgg16_1-best-classifier.h5\n",
      "Epoch 6/10\n",
      " 8/10 [=======================>......] - ETA: 33s - loss: 0.9152 - acc: 0.6263"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "model_final.fit_generator(\n",
    "train_generator,\n",
    "steps_per_epoch = steps_per_epoch,\n",
    "epochs = epochs,\n",
    "validation_data = validation_generator,\n",
    "validation_steps = valid_files.size / batch_size,\n",
    "callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
